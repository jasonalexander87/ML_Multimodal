{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VwasNrWKWq1w"
      },
      "outputs": [],
      "source": [
        "#CREATE DATA\n",
        "\n",
        "import numpy as np\n",
        "# create dummy data for training\n",
        "x_values = [i for i in range(11)]\n",
        "x_train = np.array(x_values, dtype=np.float32)\n",
        "x_train = x_train.reshape(-1, 1)\n",
        "\n",
        "y_values = [2*i + 1 for i in x_values]\n",
        "y_train = np.array(y_values, dtype=np.float32)\n",
        "y_train = y_train.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6GbLEfUcXgwn"
      },
      "outputs": [],
      "source": [
        "#CREATE MODEL\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KimZsw3SXnnk"
      },
      "outputs": [],
      "source": [
        "#DEFINE PARAMS\n",
        "inputDim = 1        # takes variable 'x' \n",
        "outputDim = 1       # takes variable 'y'\n",
        "learningRate = 0.01 \n",
        "epochs = 10\n",
        "\n",
        "model = linearRegression(inputDim, outputDim)\n",
        "criterion = torch.nn.MSELoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CY_Zj_pYD2X"
      },
      "outputs": [],
      "source": [
        "#TRAIN MODEL\n",
        "for epoch in range(epochs):\n",
        "    # Converting inputs and labels to Variable\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
        "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
        "    else:\n",
        "        inputs = Variable(torch.from_numpy(x_train))\n",
        "        labels = Variable(torch.from_numpy(y_train))\n",
        "\n",
        "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # get output from the model, given the inputs\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # get loss for the predicted output\n",
        "    loss = criterion(outputs, labels)\n",
        "    print(loss)\n",
        "    # get gradients w.r.t to parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-9a81P7YTsz"
      },
      "outputs": [],
      "source": [
        "#TEST MODEL\n",
        "with torch.no_grad(): # we don't need gradients in the testing phase\n",
        "    if torch.cuda.is_available():\n",
        "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
        "    else:\n",
        "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
        "    print(predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVGnSMYdbQfo",
        "outputId": "42a526ae-1635-4409-fcf1-e4ffc49151a3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTyRtGEdbazD",
        "outputId": "a1bdd424-9b58-4d83-e03d-b732b5fab5fa"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S3NBVAb4aqNF"
      },
      "outputs": [],
      "source": [
        "#CONVERT MODEL\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "\n",
        "script_module = torch.jit.script(model)\n",
        "script_module_optimized = optimize_for_mobile(script_module)\n",
        "script_module_optimized._save_for_lite_interpreter(\"model.ptl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "okmNH14fdF0m",
        "outputId": "faeda2cb-90de-4326-d637-fe069341cd62"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_bf4faf5a-3f62-4029-875b-dd12f4510e31\", \"model.ptl\", 3506)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('model.ptl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Pytorch_mobile.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
